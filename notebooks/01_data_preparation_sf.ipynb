{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43615738",
   "metadata": {},
   "source": [
    "# Data Preparation: San Francisco SFPD Incidents\n",
    "\n",
    "**Project:** A Tale of Two Cities - Comparative Public Safety Analysis\n",
    "\n",
    "**Purpose:** This notebook handles data loading, cleaning, preprocessing, and feature engineering for the San Francisco dataset.\n",
    "\n",
    "**Output:** Clean, analysis-ready dataset saved to `data/processed/sf_incidents_cleaned.csv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f822d0d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad751ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c84a9",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Initial Inspection\n",
    "\n",
    "We begin by loading the SFPD incident dataset and examining its structure, dimensions, and key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6be9d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 983,556 rows, 29 columns\n",
      "         Row ID       Incident Datetime Incident Date Incident Time  \\\n",
      "0  150750507041  2025/08/26 11:17:00 PM    2025/08/26         23:17   \n",
      "1  150752104134  2025/08/27 12:37:00 AM    2025/08/27         00:37   \n",
      "2  150762309027  2025/07/17 03:00:00 PM    2025/07/17         15:00   \n",
      "3  150740506244  2025/08/23 09:30:00 PM    2025/08/23         21:30   \n",
      "4  150723571000  2025/08/15 12:00:00 PM    2025/08/15         12:00   \n",
      "\n",
      "   Incident Year Incident Day of Week         Report Datetime  Incident ID  \\\n",
      "0           2025              Tuesday  2025/08/26 11:17:00 PM      1507505   \n",
      "1           2025            Wednesday  2025/08/27 12:37:00 AM      1507521   \n",
      "2           2025             Thursday  2025/08/27 11:55:00 AM      1507623   \n",
      "3           2025             Saturday  2025/08/24 02:53:00 PM      1507405   \n",
      "4           2025               Friday  2025/08/24 07:10:00 PM      1507235   \n",
      "\n",
      "   Incident Number   CAD Number  ...         CNN Police District  \\\n",
      "0        250333102          NaN  ...         NaN       Out of SF   \n",
      "1        250479881  252390049.0  ...  33557000.0            Park   \n",
      "2        250480775  252391585.0  ...  26469000.0            Park   \n",
      "3        256091227          NaN  ...  25905000.0        Northern   \n",
      "4        256090348          NaN  ...  26412000.0            Park   \n",
      "\n",
      "  Analysis Neighborhood  Supervisor District Supervisor District 2012  \\\n",
      "0                   NaN                  NaN                      NaN   \n",
      "1     Lone Mountain/USF                  1.0                      1.0   \n",
      "2     Lone Mountain/USF                  1.0                      1.0   \n",
      "3          Hayes Valley                  6.0                      5.0   \n",
      "4        Haight Ashbury                  5.0                      5.0   \n",
      "\n",
      "    Latitude   Longitude                                Point  \\\n",
      "0        NaN         NaN                                  NaN   \n",
      "1  37.780415 -122.449013  POINT (-122.449012756 37.780414581)   \n",
      "2  37.775177 -122.451355   POINT (-122.45135498 37.775177002)   \n",
      "3  37.774551 -122.422501   POINT (-122.42250061 37.774551392)   \n",
      "4  37.769661 -122.449646   POINT (-122.449645996 37.76966095)   \n",
      "\n",
      "               data_as_of          data_loaded_at  \n",
      "0  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "1  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "2  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "3  2025/08/27 09:38:07 AM  2025/08/28 09:53:00 AM  \n",
      "4  2025/08/27 09:38:07 AM  2025/08/28 09:53:00 AM  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file into a DataFrame\n",
    "file_path = '../data/raw/sfpd_incidents.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6e7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 983556 entries, 0 to 983555\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Row ID                    983556 non-null  int64  \n",
      " 1   Incident Datetime         983556 non-null  object \n",
      " 2   Incident Date             983556 non-null  object \n",
      " 3   Incident Time             983556 non-null  object \n",
      " 4   Incident Year             983556 non-null  int64  \n",
      " 5   Incident Day of Week      983556 non-null  object \n",
      " 6   Report Datetime           983556 non-null  object \n",
      " 7   Incident ID               983556 non-null  int64  \n",
      " 8   Incident Number           983556 non-null  int64  \n",
      " 9   CAD Number                762527 non-null  float64\n",
      " 10  Report Type Code          983556 non-null  object \n",
      " 11  Report Type Description   983556 non-null  object \n",
      " 12  Filed Online              193890 non-null  object \n",
      " 13  Incident Code             983556 non-null  int64  \n",
      " 14  Incident Category         982137 non-null  object \n",
      " 15  Incident Subcategory      982137 non-null  object \n",
      " 16  Incident Description      983556 non-null  object \n",
      " 17  Resolution                983556 non-null  object \n",
      " 18  Intersection              929028 non-null  object \n",
      " 19  CNN                       929028 non-null  float64\n",
      " 20  Police District           983556 non-null  object \n",
      " 21  Analysis Neighborhood     928737 non-null  object \n",
      " 22  Supervisor District       928413 non-null  float64\n",
      " 23  Supervisor District 2012  928939 non-null  float64\n",
      " 24  Latitude                  929028 non-null  float64\n",
      " 25  Longitude                 929028 non-null  float64\n",
      " 26  Point                     929028 non-null  object \n",
      " 27  data_as_of                983556 non-null  object \n",
      " 28  data_loaded_at            983556 non-null  object \n",
      "dtypes: float64(6), int64(5), object(18)\n",
      "memory usage: 217.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a1865",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "### 2.1 DateTime Processing\n",
    "The dataset contains separate date and time columns. We'll combine these into a single DateTime index for efficient time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114d30a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime index created successfully\n",
      "                           Row ID       Incident Datetime Incident Date  \\\n",
      "Incident DateTime                                                         \n",
      "2025-08-26 23:17:00  150750507041  2025/08/26 11:17:00 PM    2025-08-26   \n",
      "2025-08-27 00:37:00  150752104134  2025/08/27 12:37:00 AM    2025-08-27   \n",
      "2025-07-17 15:00:00  150762309027  2025/07/17 03:00:00 PM    2025-07-17   \n",
      "2025-08-23 21:30:00  150740506244  2025/08/23 09:30:00 PM    2025-08-23   \n",
      "2025-08-15 12:00:00  150723571000  2025/08/15 12:00:00 PM    2025-08-15   \n",
      "\n",
      "                    Incident Time  Incident Year Incident Day of Week  \\\n",
      "Incident DateTime                                                       \n",
      "2025-08-26 23:17:00         23:17           2025              Tuesday   \n",
      "2025-08-27 00:37:00         00:37           2025            Wednesday   \n",
      "2025-07-17 15:00:00         15:00           2025             Thursday   \n",
      "2025-08-23 21:30:00         21:30           2025             Saturday   \n",
      "2025-08-15 12:00:00         12:00           2025               Friday   \n",
      "\n",
      "                            Report Datetime  Incident ID  Incident Number  \\\n",
      "Incident DateTime                                                           \n",
      "2025-08-26 23:17:00  2025/08/26 11:17:00 PM      1507505        250333102   \n",
      "2025-08-27 00:37:00  2025/08/27 12:37:00 AM      1507521        250479881   \n",
      "2025-07-17 15:00:00  2025/08/27 11:55:00 AM      1507623        250480775   \n",
      "2025-08-23 21:30:00  2025/08/24 02:53:00 PM      1507405        256091227   \n",
      "2025-08-15 12:00:00  2025/08/24 07:10:00 PM      1507235        256090348   \n",
      "\n",
      "                      CAD Number  ...         CNN Police District  \\\n",
      "Incident DateTime                 ...                               \n",
      "2025-08-26 23:17:00          NaN  ...         NaN       Out of SF   \n",
      "2025-08-27 00:37:00  252390049.0  ...  33557000.0            Park   \n",
      "2025-07-17 15:00:00  252391585.0  ...  26469000.0            Park   \n",
      "2025-08-23 21:30:00          NaN  ...  25905000.0        Northern   \n",
      "2025-08-15 12:00:00          NaN  ...  26412000.0            Park   \n",
      "\n",
      "                    Analysis Neighborhood  Supervisor District  \\\n",
      "Incident DateTime                                                \n",
      "2025-08-26 23:17:00                   NaN                  NaN   \n",
      "2025-08-27 00:37:00     Lone Mountain/USF                  1.0   \n",
      "2025-07-17 15:00:00     Lone Mountain/USF                  1.0   \n",
      "2025-08-23 21:30:00          Hayes Valley                  6.0   \n",
      "2025-08-15 12:00:00        Haight Ashbury                  5.0   \n",
      "\n",
      "                    Supervisor District 2012   Latitude   Longitude  \\\n",
      "Incident DateTime                                                     \n",
      "2025-08-26 23:17:00                      NaN        NaN         NaN   \n",
      "2025-08-27 00:37:00                      1.0  37.780415 -122.449013   \n",
      "2025-07-17 15:00:00                      1.0  37.775177 -122.451355   \n",
      "2025-08-23 21:30:00                      5.0  37.774551 -122.422501   \n",
      "2025-08-15 12:00:00                      5.0  37.769661 -122.449646   \n",
      "\n",
      "                                                   Point  \\\n",
      "Incident DateTime                                          \n",
      "2025-08-26 23:17:00                                  NaN   \n",
      "2025-08-27 00:37:00  POINT (-122.449012756 37.780414581)   \n",
      "2025-07-17 15:00:00   POINT (-122.45135498 37.775177002)   \n",
      "2025-08-23 21:30:00   POINT (-122.42250061 37.774551392)   \n",
      "2025-08-15 12:00:00   POINT (-122.449645996 37.76966095)   \n",
      "\n",
      "                                 data_as_of          data_loaded_at  \n",
      "Incident DateTime                                                    \n",
      "2025-08-26 23:17:00  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "2025-08-27 00:37:00  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "2025-07-17 15:00:00  2025/08/28 09:38:07 AM  2025/08/29 09:53:03 AM  \n",
      "2025-08-23 21:30:00  2025/08/27 09:38:07 AM  2025/08/28 09:53:00 AM  \n",
      "2025-08-15 12:00:00  2025/08/27 09:38:07 AM  2025/08/28 09:53:00 AM  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Incident Date' to datetime objects\n",
    "df['Incident Date'] = pd.to_datetime(df['Incident Date'])\n",
    "\n",
    "# Combine date and time into a single column\n",
    "df['Incident DateTime'] = pd.to_datetime(\n",
    "    df['Incident Date'].dt.strftime('%Y-%m-%d') + ' ' + df['Incident Time']\n",
    ")\n",
    "\n",
    "# Set as index\n",
    "df.set_index('Incident DateTime', inplace=True)\n",
    "\n",
    "print(\"DateTime index created successfully\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43670662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after cleanup: 27\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 983556 entries, 2025-08-26 23:17:00 to 2024-06-01 12:00:00\n",
      "Data columns (total 27 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Row ID                    983556 non-null  int64  \n",
      " 1   Incident Datetime         983556 non-null  object \n",
      " 2   Incident Year             983556 non-null  int64  \n",
      " 3   Incident Day of Week      983556 non-null  object \n",
      " 4   Report Datetime           983556 non-null  object \n",
      " 5   Incident ID               983556 non-null  int64  \n",
      " 6   Incident Number           983556 non-null  int64  \n",
      " 7   CAD Number                762527 non-null  float64\n",
      " 8   Report Type Code          983556 non-null  object \n",
      " 9   Report Type Description   983556 non-null  object \n",
      " 10  Filed Online              193890 non-null  object \n",
      " 11  Incident Code             983556 non-null  int64  \n",
      " 12  Incident Category         982137 non-null  object \n",
      " 13  Incident Subcategory      982137 non-null  object \n",
      " 14  Incident Description      983556 non-null  object \n",
      " 15  Resolution                983556 non-null  object \n",
      " 16  Intersection              929028 non-null  object \n",
      " 17  CNN                       929028 non-null  float64\n",
      " 18  Police District           983556 non-null  object \n",
      " 19  Analysis Neighborhood     928737 non-null  object \n",
      " 20  Supervisor District       928413 non-null  float64\n",
      " 21  Supervisor District 2012  928939 non-null  float64\n",
      " 22  Latitude                  929028 non-null  float64\n",
      " 23  Longitude                 929028 non-null  float64\n",
      " 24  Point                     929028 non-null  object \n",
      " 25  data_as_of                983556 non-null  object \n",
      " 26  data_loaded_at            983556 non-null  object \n",
      "dtypes: float64(6), int64(5), object(16)\n",
      "memory usage: 210.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop redundant date/time columns\n",
    "df.drop(['Incident DateTime', 'Incident Date', 'Incident Time'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"Columns after cleanup: {len(df.columns)}\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62623269",
   "metadata": {},
   "source": [
    "### 2.2 Handling Missing Values\n",
    "Before proceeding with analysis, we need to identify and handle missing data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2883a5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Filed Online                80.286837\n",
      "CAD Number                  22.472437\n",
      "Supervisor District          5.606493\n",
      "Analysis Neighborhood        5.573551\n",
      "Supervisor District 2012     5.553014\n",
      "Intersection                 5.543965\n",
      "CNN                          5.543965\n",
      "Latitude                     5.543965\n",
      "Longitude                    5.543965\n",
      "Point                        5.543965\n",
      "Incident Category            0.144272\n",
      "Incident Subcategory         0.144272\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate missing value percentages\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_percentage[missing_percentage > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3002eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 columns with >20% missing values:\n",
      "['CAD Number', 'Filed Online']\n",
      "\n",
      "Columns remaining: 25\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with high percentage of missing values (>20%)\n",
    "columns_to_drop = missing_percentage[missing_percentage > 20].index.tolist()\n",
    "\n",
    "if columns_to_drop:\n",
    "    df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    print(f\"Dropped {len(columns_to_drop)} columns with >20% missing values:\")\n",
    "    print(columns_to_drop)\n",
    "else:\n",
    "    print(\"No columns with >20% missing values\")\n",
    "\n",
    "print(f\"\\nColumns remaining: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38285eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped: 56,580 (5.75%)\n",
      "Clean dataset: 926,976 rows\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with remaining missing values\n",
    "rows_before = len(df)\n",
    "df.dropna(inplace=True)\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f\"Rows dropped: {rows_before - rows_after:,} ({((rows_before - rows_after)/rows_before)*100:.2f}%)\")\n",
    "print(f\"Clean dataset: {rows_after:,} rows\")\n",
    "print(f\"Remaining missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e825ba6",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Extract temporal features for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d19919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features created:\n",
      "                     Hour Day of Week Name Month Name  Year  Is Weekend\n",
      "Incident DateTime                                                      \n",
      "2025-08-27 00:37:00     0        Wednesday     August  2025           0\n",
      "2025-07-17 15:00:00    15         Thursday       July  2025           0\n",
      "2025-08-23 21:30:00    21         Saturday     August  2025           1\n",
      "2025-08-15 12:00:00    12           Friday     August  2025           0\n",
      "2025-08-15 21:45:00    21           Friday     August  2025           0\n"
     ]
    }
   ],
   "source": [
    "# Create temporal features from the DateTime index\n",
    "df['Hour'] = df.index.hour\n",
    "df['Day'] = df.index.day\n",
    "df['Month'] = df.index.month\n",
    "df['Year'] = df.index.year\n",
    "df['Day of Week'] = df.index.dayofweek  # Monday=0, Sunday=6\n",
    "df['Day of Week Name'] = df.index.day_name()\n",
    "df['Month Name'] = df.index.month_name()\n",
    "df['Quarter'] = df.index.quarter\n",
    "df['Is Weekend'] = df['Day of Week'].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "print(df[['Hour', 'Day of Week Name', 'Month Name', 'Year', 'Is Weekend']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ef290",
   "metadata": {},
   "source": [
    "# 6. Category Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a89be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original unique SF Categories: 49\n",
      "\n",
      "High-level categories created:\n",
      "Incident_High_Level_Category\n",
      "Theft/Property            443411\n",
      "Non-Criminal/Admin        172317\n",
      "Violent                   112849\n",
      "Disturbance/Suspicious    103055\n",
      "Traffic/Vehicle            36902\n",
      "Fraud                      32021\n",
      "Other                      26421\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nOriginal unique SF Categories: {df['Incident Category'].nunique()}\")\n",
    "\n",
    "def map_high_level_category(cat):\n",
    "    cat = str(cat).upper()\n",
    "    \n",
    "    # Violent\n",
    "    if cat in ['ASSAULT', 'ROBBERY', 'HOMICIDE', 'SEX OFFENSE', 'OFFENCES AGAINST THE FAMILY AND CHILDREN', 'WEAPONS OFFENSE', 'WEAPONS CARRYING ETC']:\n",
    "        return 'Violent'\n",
    "    \n",
    "    # Theft/Property\n",
    "    if cat in ['LARCENY THEFT', 'BURGLARY', 'MOTOR VEHICLE THEFT', 'MALICIOUS MISCHIEF', 'STOLEN PROPERTY', 'ARSON']:\n",
    "        return 'Theft/Property'\n",
    "    \n",
    "    # Disturbance/Suspicious\n",
    "    if cat in ['SUSPICIOUS OCC', 'DISORDERLY CONDUCT', 'MISSING PERSON', 'DRUG OFFENSE', 'MISCELLANEOUS INVESTIGATION']:\n",
    "        return 'Disturbance/Suspicious'\n",
    "\n",
    "    # Traffic/Vehicle\n",
    "    if cat in ['TRAFFIC VIOLATION ARREST', 'RECOVERED VEHICLE', 'DRIVING UNDER THE INFLUENCE']:\n",
    "        return 'Traffic/Vehicle'\n",
    "    \n",
    "    # Fraud\n",
    "    if cat == 'FRAUD':\n",
    "        return 'Fraud'\n",
    "        \n",
    "    # Non-Criminal / Admin\n",
    "    if cat in ['NON-CRIMINAL', 'WARRANT', 'LOST PROPERTY', 'CASE CLOSURE', 'OTHER MISCELLANEOUS', 'OTHER']:\n",
    "        return 'Non-Criminal/Admin'\n",
    "\n",
    "    # All others fall into a general 'Other'\n",
    "    return 'Other'\n",
    "\n",
    "# Apply the mapping\n",
    "df['Incident_High_Level_Category'] = df['Incident Category'].apply(map_high_level_category)\n",
    "\n",
    "print(\"\\nHigh-level categories created:\")\n",
    "print(df['Incident_High_Level_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6beac",
   "metadata": {},
   "source": [
    "# 7. Final Schema Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa17fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting final schema synchronization...\n",
      "Columns before cleanup: 35\n",
      "Columns after cleanup: 15\n",
      "Final column list:\n",
      "['Incident_High_Level_Category', 'Resolution', 'Neighborhood', 'Police_District', 'Latitude', 'Longitude', 'Hour', 'Day', 'Month', 'Year', 'Day_of_Week', 'Day_of_Week_Name', 'Month_Name', 'Quarter', 'Is_Weekend']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting final schema synchronization...\")\n",
    "print(f\"Columns before cleanup: {len(df.columns)}\")\n",
    "\n",
    "# Define final columns to keep\n",
    "columns_to_keep = {\n",
    "    # Key Fields\n",
    "    'Incident_High_Level_Category': 'Incident_High_Level_Category',\n",
    "    'Resolution': 'Resolution',\n",
    "    'Analysis Neighborhood': 'Neighborhood',\n",
    "    'Police District': 'Police_District',\n",
    "    'Latitude': 'Latitude',\n",
    "    'Longitude': 'Longitude',\n",
    "    \n",
    "    # Temporal Features\n",
    "    'Hour': 'Hour',\n",
    "    'Day': 'Day',\n",
    "    'Month': 'Month',\n",
    "    'Year': 'Year',\n",
    "    'Day of Week': 'Day_of_Week',\n",
    "    'Day of Week Name': 'Day_of_Week_Name',\n",
    "    'Month Name': 'Month_Name',\n",
    "    'Quarter': 'Quarter',\n",
    "    'Is Weekend': 'Is_Weekend'\n",
    "}\n",
    "\n",
    "# Filter DataFrame\n",
    "df_final = df[columns_to_keep.keys()].copy()\n",
    "\n",
    "# Rename columns for perfect sync\n",
    "df_final.rename(columns=columns_to_keep, inplace=True)\n",
    "\n",
    "print(f\"Columns after cleanup: {len(df_final.columns)}\")\n",
    "print(\"Final column list:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c50e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before final duplicate drop: 926,976\n",
      "Found 103,435 duplicates in df_final. Dropping...\n",
      "New final row count: 823,541\n"
     ]
    }
   ],
   "source": [
    "# Drop Final Duplicates ===\n",
    "print(f\"Rows before final duplicate drop: {len(df_final):,}\")\n",
    "duplicates_final = df_final.duplicated().sum()\n",
    "\n",
    "if duplicates_final > 0:\n",
    "    print(f\"Found {duplicates_final:,} duplicates in df_final. Dropping...\")\n",
    "    df_final.drop_duplicates(inplace=True)\n",
    "    print(f\"New final row count: {len(df_final):,}\")\n",
    "else:\n",
    "    print(\"No final duplicates found in df_final.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d14e9",
   "metadata": {},
   "source": [
    "# 8. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3dfa2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL CLEAN DATASET SUMMARY\n",
      "============================================================\n",
      "Total Rows: 823,541\n",
      "Total Columns: 15\n",
      "Date Range: 2018-01-01 00:00:00 to 2025-11-16 23:50:00\n",
      "Missing Values: 0\n",
      "Duplicate Rows: 0\n",
      "\n",
      "Column List:\n",
      "['Incident_High_Level_Category', 'Resolution', 'Neighborhood', 'Police_District', 'Latitude', 'Longitude', 'Hour', 'Day', 'Month', 'Year', 'Day_of_Week', 'Day_of_Week_Name', 'Month_Name', 'Quarter', 'Is_Weekend']\n"
     ]
    }
   ],
   "source": [
    "# Final data quality summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL CLEAN DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Rows: {len(df_final):,}\")\n",
    "print(f\"Total Columns: {len(df_final.columns)}\")\n",
    "print(f\"Date Range: {df_final.index.min()} to {df_final.index.max()}\")\n",
    "print(f\"Missing Values: {df_final.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate Rows: {df_final.duplicated().sum()}\")\n",
    "print(\"\\nColumn List:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d55323",
   "metadata": {},
   "source": [
    "# 9. Save Processed Data\n",
    "\n",
    "Save the clean dataset for use by team members in downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a25a90f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean dataset saved to: ../data/processed/sf_incidents_cleaned.csv\n",
      "File size: 110.39 MB\n"
     ]
    }
   ],
   "source": [
    "# Create processed data directory if it doesn't exist\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_final.to_csv(output_dir / 'sf_incidents_cleaned.csv')\n",
    "\n",
    "print(f\"✅ Clean dataset saved to: {output_dir / 'sf_incidents_cleaned.csv'}\")\n",
    "print(f\"File size: {(output_dir / 'sf_incidents_cleaned.csv').stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c8a35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Note:\n",
    "\n",
    "**For Team Members:**\n",
    "- Load this clean dataset using: `pd.read_csv('../data/processed/sf_incidents_cleaned.csv', index_col='Incident DateTime', parse_dates=True)`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
